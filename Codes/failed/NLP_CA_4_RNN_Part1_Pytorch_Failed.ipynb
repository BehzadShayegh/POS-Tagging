{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-CA#4-RNN-Part1-Pytorch-Failed.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "697d5f7c8c02490dbef89e0f9ea633c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9c9a6a8a4e84fdb858aea5e3299a605",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9bb7e90a28204440bc6a0ca1057bde5e",
              "IPY_MODEL_189d4e34516640d89a4f364a50864ead"
            ]
          }
        },
        "f9c9a6a8a4e84fdb858aea5e3299a605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9bb7e90a28204440bc6a0ca1057bde5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70e7c33e85634648b81d2fb0b8e0e689",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b23483061ab46fd9797cedb4b9d0eea"
          }
        },
        "189d4e34516640d89a4f364a50864ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ddfc3014c6a482187584d1bb57c6f68",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [6:57:02&lt;00:00, 1251.14s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8af94def1c04cb39fc3a34c3efde1d9"
          }
        },
        "70e7c33e85634648b81d2fb0b8e0e689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b23483061ab46fd9797cedb4b9d0eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ddfc3014c6a482187584d1bb57c6f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8af94def1c04cb39fc3a34c3efde1d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "isuEV7nQGm1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "X = json.load(open('RNN_train_x.json'))\n",
        "Y = json.load(open('RNN_train_y.json'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRFMsPLETOIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "\n",
        "class translator :\n",
        "    def __init__(self, words, min_count, empty=False) :\n",
        "      if not empty :\n",
        "        npwords = np.array(words)\n",
        "        count = [(word,(npwords==word).sum()) for word in tqdm(np.unique(words))]\n",
        "        count = sorted(count, key=lambda x: x[1], reverse=True)\n",
        "        d = -1\n",
        "        while True :\n",
        "          d += 1\n",
        "          if count[d][1] < min_count :\n",
        "            break\n",
        "        self.dim = d+1\n",
        "        self.mapping = {count[i][0] : i for i in range(d)}\n",
        "\n",
        "    def one_hot(self, i) :\n",
        "      a = torch.zeros(self.dim)\n",
        "      a[i] = 1\n",
        "      return a\n",
        "\n",
        "    def __getitem__(self, i, tensor=True) :\n",
        "        if type(i)==type('') :\n",
        "          if tensor :\n",
        "            return self.one_hot(self.mapping.get(i, self.dim-1))\n",
        "          else :\n",
        "            return self.one_hot(self.mapping.get(i, self.dim-1)).tolist()\n",
        "        \n",
        "        elif type(i)==type(1) :\n",
        "          if tensor :\n",
        "            return self.one_hot(i)\n",
        "          else :\n",
        "            return self.one_hot(i).tolist()\n",
        "        \n",
        "        elif type(i)==type(list()) :\n",
        "          if tensor :\n",
        "            return torch.tensor(list(map(lambda x: self.__getitem__(x, False), i)))\n",
        "          else :\n",
        "            return list(map(lambda x: self.__getitem__(x, False), i))\n",
        "\n",
        "        else :\n",
        "            return self.__getitem__(i.tolist())\n",
        "\n",
        "    def get_item(self, i) :\n",
        "        if type(i)==type('') :\n",
        "            return self.mapping.get(i, self.dim-1)\n",
        "        if type(i)==type(1) :\n",
        "            return i\n",
        "        elif type(i)==type(list()) :\n",
        "            return torch.tensor(list(map(self.get_item, i)))\n",
        "        else :\n",
        "            return self.get_item(i.tolist())\n",
        "\n",
        "    def save_to_file(self, name) :\n",
        "      json.dump({'dim': self.dim, 'mapping': self.mapping}, open(name,'w'))\n",
        "\n",
        "    @classmethod\n",
        "    def load_from_file(cls, name) :\n",
        "      f = json.load(open(name))\n",
        "      self = cls([],0,True)\n",
        "      self.dim = f['dim']\n",
        "      self.mapping = f['mapping']\n",
        "      return self\n",
        "\n",
        "onehoter = translator.load_from_file('RNN_one_hoter.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkomAmaFGzZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pos_indexer = json.load(open('pos_indexer.json'))\n",
        "def pos_index(l) :\n",
        "  return list(map(pos_indexer.__getitem__, l))\n",
        "pos_names = pd.read_csv('pos_list.csv')\n",
        "def pos_name(l) :\n",
        "  return list(map(lambda x: pos_names.iloc[int(x)][0], l))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXUgsMJuNEP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MyRNN(nn.Module):\n",
        "    def __init__(self, n_inputs, n_neurons, n_classes):\n",
        "        super(MyRNN, self).__init__()\n",
        "        \n",
        "        self.rnn = nn.RNNCell(n_inputs, n_neurons)\n",
        "        self.l = nn.Linear(n_neurons, n_classes)\n",
        "        self.hx = torch.randn(1, n_neurons)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        output = []\n",
        "\n",
        "        # for each time step\n",
        "        for i in range(len(X)):\n",
        "            self.hx = self.rnn(X[i].reshape(1,-1), self.hx)\n",
        "            o = torch.sigmoid(self.l(self.hx))\n",
        "            output.append(o)\n",
        "        \n",
        "        return output, self.hx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de1ge9oYjp63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import trange\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def usable_data(X,Y) :\n",
        "  x = onehoter[X]\n",
        "  y = torch.tensor(pos_index(Y))\n",
        "  return x,y\n",
        "\n",
        "def train_step(model, X, Y, lr) :\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "  X,Y = usable_data(X,Y)\n",
        "  size = len(Y)\n",
        "  optimizer.zero_grad()\n",
        "  outputs, _ = model(X)\n",
        "  loss = list(map(lambda i: criterion(outputs[i], torch.tensor([Y[i]])), range(size)))\n",
        "  loss = sum(loss) / size\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  model.hx = model.hx.detach()\n",
        "  return loss\n",
        "\n",
        "def train(model, X, Y, lr, epoch) :\n",
        "  length = len(Y)\n",
        "  index = np.arange(length)\n",
        "  losses = list()\n",
        "  for e in tqdm(range(epoch)) :\n",
        "      np.random.shuffle(index)\n",
        "      ls = list()\n",
        "      for i in index :\n",
        "        l = train_step(model, X[i], Y[i], lr)\n",
        "        l = round(float(l.data),3)\n",
        "        ls.append(l)\n",
        "      losses.append(sum(ls)/len(ls))\n",
        "  return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81QtxizwTOb7",
        "colab_type": "code",
        "outputId": "6e6dcf64-828f-4a68-b6e6-e7ef4ed5935c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "697d5f7c8c02490dbef89e0f9ea633c3",
            "f9c9a6a8a4e84fdb858aea5e3299a605",
            "9bb7e90a28204440bc6a0ca1057bde5e",
            "189d4e34516640d89a4f364a50864ead",
            "70e7c33e85634648b81d2fb0b8e0e689",
            "5b23483061ab46fd9797cedb4b9d0eea",
            "4ddfc3014c6a482187584d1bb57c6f68",
            "e8af94def1c04cb39fc3a34c3efde1d9"
          ]
        }
      },
      "source": [
        "model = MyRNN(onehoter.dim, 60, len(pos_indexer))\n",
        "losses = train(model,X,Y,0.01,20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "697d5f7c8c02490dbef89e0f9ea633c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=20), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ackXdH-TmMBv",
        "colab_type": "code",
        "outputId": "fe2832d8-7bf3-43a6-94ac-0e03ad7504d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "import json\n",
        "json.dump(losses,open('losses.json','w'))\n",
        "from google.colab import files\n",
        "files.download('losses.json') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b7e643bbcb89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'losses.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'losses.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC8RHv166rDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.titile('RNN trainong')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn4eziti6h5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses += train(model,X,Y,0.001,10)\n",
        "json.dump(losses,open('losses.json','w'))\n",
        "files.download('losses.json') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbrzGGjyTOk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)\n",
        "plt.titile('RNN trainong')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzyV2hKkTQ9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def test_step(model, X, Y) :\n",
        "#   X,Y = usable_data(X,Y)\n",
        "#   size = len(Y)\n",
        "#   with torch.no_grad():\n",
        "#       outputs,_ = model(X)\n",
        "#       _, predicted = torch.max(outputs.data, 1)\n",
        "      \n",
        "#   model.hx = model.hx.detach()\n",
        "#   return loss\n",
        "\n",
        "# def Test(NET, testloader) :\n",
        "#   correct = 0\n",
        "#   total = 0\n",
        "#   with torch.no_grad():\n",
        "#       for data in testloader:\n",
        "#           images, labels = data\n",
        "#           images, labels = images.to(device), labels.to(device)\n",
        "#           outputs = NET(images)\n",
        "#           _, predicted = torch.max(outputs.data, 1)\n",
        "#           total += labels.size(0)\n",
        "#           correct += (predicted == labels).sum().item()\n",
        "\n",
        "#   print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "\n",
        "# def train_step(model, X, Y, lr) :\n",
        "#   optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "#   X,Y = usable_data(X,Y)\n",
        "#   X,Y = X.to(device), Y.to(device)\n",
        "#   size = len(Y)\n",
        "#   optimizer.zero_grad()\n",
        "#   outputs, _ = model(X)\n",
        "#   loss = list(map(lambda i: criterion(outputs[i], torch.tensor([Y[i]])), range(size)))\n",
        "#   loss = sum(loss) / size\n",
        "#   loss.backward()\n",
        "#   optimizer.step()\n",
        "#   model.hx = model.hx.detach()\n",
        "#   return loss\n",
        "\n",
        "# def train(model, X, Y, lr, epoch) :\n",
        "#   length = len(Y)\n",
        "#   index = np.arange(length)\n",
        "#   losses = list()\n",
        "#   for e in tqdm(range(epoch)) :\n",
        "#       np.random.shuffle(index)\n",
        "#       ls = list()\n",
        "#       for i in tqdm(index) :\n",
        "#         l = train_step(model, X[i], Y[i], lr)\n",
        "#         l = round(float(l.data),3)\n",
        "#         ls.append(l)\n",
        "#       losses.append(sum(ls)/len(ls))\n",
        "#   return losses"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}